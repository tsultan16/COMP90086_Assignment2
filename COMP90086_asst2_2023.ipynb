{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b4e030d",
   "metadata": {},
   "source": [
    "### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP90086 Computer Vision, 2023 Semester 2\n",
    "\n",
    "## Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b592bd",
   "metadata": {},
   "source": [
    "**Student Name:**    `TANZID SULTAN`\n",
    "\n",
    "**Student ID:**     `1430660`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf1c1ce",
   "metadata": {},
   "source": [
    "## This iPython notebook is a template which you should use for your Assignment 2 submission. This file should be submitted at the **Assignment 2: Code** link on the LMS.\n",
    "\n",
    "In addition to this file, you should submit a written report explaining your results at the **Assignment 2: Report** link on the LMS. Please see the assignment specification for details on what must be included in the report for each question.\n",
    "\n",
    "*Adding proper comments to your code is MANDATORY.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920cbf26",
   "metadata": {},
   "source": [
    "### 1. CNN training\n",
    "\n",
    "The following code section will load the dataset from a folder that you specify. You may change the batch sizes and add additional data augmentation steps here if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b59fecf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1440 images belonging to 8 classes.\n",
      "Found 320 images belonging to 8 classes.\n",
      "Found 320 images belonging to 8 classes.\n",
      "{'coast': 0, 'forest': 1, 'highway': 2, 'insidecity': 3, 'mountain': 4, 'opencountry': 5, 'street': 6, 'tallbuilding': 7}\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_dir = 'scene32' # SPECIFY YOUR PATH TO THE DATASET\n",
    "batch_size = 40\n",
    "\n",
    "# Data generator for training\n",
    "# Additional data augmentation may be added here if desired\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "# Data generator for test\n",
    "# DO NOT USE DATA AUGMENTATION WITH TEST SET\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "# Generate training data from 'train' directory\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "        data_dir+'/train',\n",
    "        target_size=(32,32),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Generate vaildation data from 'valid' directory\n",
    "val_data = test_datagen.flow_from_directory(\n",
    "        data_dir+'/valid',\n",
    "        target_size=(32,32),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Generate test data from 'test' directory\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "        data_dir+'/test',\n",
    "        target_size=(32,32),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "# Output list of class names\n",
    "class_names_and_indices = train_data.class_indices\n",
    "print(class_names_and_indices)\n",
    "\n",
    "# Note: To train a model with the dataset loaded above, pass the train and val\n",
    "# datasets to the fit() function, like so:\n",
    "# myModel.fit(train_data, validation_data=val_data, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18a21a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# library imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make sure GPU is available\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e42a46",
   "metadata": {},
   "source": [
    "#### CNN model according to specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "365ac07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 30, 30, 16)        448       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                200768    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 204,056\n",
      "Trainable params: 204,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "cnn1 = keras.Sequential(\n",
    "    [\n",
    "        layers.Input((32,32,3)),                                       # input image shape is 32x32x3  \n",
    "        layers.Conv2D(16, (3,3), padding='valid', activation='relu'),\n",
    "        layers.Conv2D(16, (3,3), padding='valid', activation='relu'),\n",
    "        layers.MaxPooling2D((2,2), strides=(2,2), padding='valid'),\n",
    "        layers.Flatten(),                                              # unravel the 3d tensor from the previous layer output\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(8, activation='softmax')                          # output layer with 8 neurons, corresponding to the 8 categories\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# configure the model\n",
    "cnn1.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "# display summary\n",
    "cnn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "170fef61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 15:31:59.349482: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-09-01 15:32:01.807374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-09-01 15:32:04.230162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-09-01 15:32:04.242730: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f86260ad910 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-01 15:32:04.242766: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2023-09-01 15:32:04.259235: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-01 15:32:04.531832: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 7s - loss: 1.8882 - accuracy: 0.3056 - val_loss: 1.6711 - val_accuracy: 0.4000 - 7s/epoch - 183ms/step\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 15:32:05.804897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 0s - loss: 1.5343 - accuracy: 0.4542 - val_loss: 1.4090 - val_accuracy: 0.5188 - 285ms/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "36/36 - 0s - loss: 1.3021 - accuracy: 0.5562 - val_loss: 1.2388 - val_accuracy: 0.5562 - 279ms/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "36/36 - 0s - loss: 1.1703 - accuracy: 0.6062 - val_loss: 1.1341 - val_accuracy: 0.5906 - 261ms/epoch - 7ms/step\n",
      "Epoch 5/50\n",
      "36/36 - 0s - loss: 0.9883 - accuracy: 0.6812 - val_loss: 1.0196 - val_accuracy: 0.6438 - 264ms/epoch - 7ms/step\n",
      "Epoch 6/50\n",
      "36/36 - 0s - loss: 0.9024 - accuracy: 0.6868 - val_loss: 1.0155 - val_accuracy: 0.6531 - 256ms/epoch - 7ms/step\n",
      "Epoch 7/50\n",
      "36/36 - 0s - loss: 0.8358 - accuracy: 0.7201 - val_loss: 0.9692 - val_accuracy: 0.6719 - 246ms/epoch - 7ms/step\n",
      "Epoch 8/50\n",
      "36/36 - 0s - loss: 0.7318 - accuracy: 0.7701 - val_loss: 0.9025 - val_accuracy: 0.6750 - 275ms/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "36/36 - 0s - loss: 0.6845 - accuracy: 0.7743 - val_loss: 0.9649 - val_accuracy: 0.6469 - 277ms/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "36/36 - 0s - loss: 0.6305 - accuracy: 0.7993 - val_loss: 0.9266 - val_accuracy: 0.6719 - 263ms/epoch - 7ms/step\n",
      "Epoch 11/50\n",
      "36/36 - 0s - loss: 0.5451 - accuracy: 0.8326 - val_loss: 0.8403 - val_accuracy: 0.6750 - 261ms/epoch - 7ms/step\n",
      "Epoch 12/50\n",
      "36/36 - 0s - loss: 0.4759 - accuracy: 0.8458 - val_loss: 0.9118 - val_accuracy: 0.6562 - 253ms/epoch - 7ms/step\n",
      "Epoch 13/50\n",
      "36/36 - 0s - loss: 0.4478 - accuracy: 0.8521 - val_loss: 0.8941 - val_accuracy: 0.6750 - 255ms/epoch - 7ms/step\n",
      "Epoch 14/50\n",
      "36/36 - 0s - loss: 0.3921 - accuracy: 0.8799 - val_loss: 0.8889 - val_accuracy: 0.6938 - 284ms/epoch - 8ms/step\n",
      "Epoch 15/50\n",
      "36/36 - 0s - loss: 0.3510 - accuracy: 0.9021 - val_loss: 0.8979 - val_accuracy: 0.6750 - 251ms/epoch - 7ms/step\n",
      "Epoch 16/50\n",
      "36/36 - 0s - loss: 0.3353 - accuracy: 0.8944 - val_loss: 0.9757 - val_accuracy: 0.6562 - 269ms/epoch - 7ms/step\n",
      "Epoch 17/50\n",
      "36/36 - 0s - loss: 0.3007 - accuracy: 0.9097 - val_loss: 0.8806 - val_accuracy: 0.6969 - 280ms/epoch - 8ms/step\n",
      "Epoch 18/50\n",
      "36/36 - 0s - loss: 0.2412 - accuracy: 0.9403 - val_loss: 0.8601 - val_accuracy: 0.6875 - 254ms/epoch - 7ms/step\n",
      "Epoch 19/50\n",
      "36/36 - 0s - loss: 0.1954 - accuracy: 0.9556 - val_loss: 0.9401 - val_accuracy: 0.6906 - 248ms/epoch - 7ms/step\n",
      "Epoch 20/50\n",
      "36/36 - 0s - loss: 0.1831 - accuracy: 0.9590 - val_loss: 0.9481 - val_accuracy: 0.6969 - 269ms/epoch - 7ms/step\n",
      "Epoch 21/50\n",
      "36/36 - 0s - loss: 0.1691 - accuracy: 0.9618 - val_loss: 0.9309 - val_accuracy: 0.6969 - 248ms/epoch - 7ms/step\n",
      "Epoch 22/50\n",
      "36/36 - 0s - loss: 0.1306 - accuracy: 0.9743 - val_loss: 0.9483 - val_accuracy: 0.6906 - 256ms/epoch - 7ms/step\n",
      "Epoch 23/50\n",
      "36/36 - 0s - loss: 0.1260 - accuracy: 0.9750 - val_loss: 1.0107 - val_accuracy: 0.6969 - 258ms/epoch - 7ms/step\n",
      "Epoch 24/50\n",
      "36/36 - 0s - loss: 0.1083 - accuracy: 0.9819 - val_loss: 1.0157 - val_accuracy: 0.6750 - 258ms/epoch - 7ms/step\n",
      "Epoch 25/50\n",
      "36/36 - 0s - loss: 0.1183 - accuracy: 0.9771 - val_loss: 1.0847 - val_accuracy: 0.6687 - 276ms/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "36/36 - 0s - loss: 0.0860 - accuracy: 0.9882 - val_loss: 1.1627 - val_accuracy: 0.6781 - 253ms/epoch - 7ms/step\n",
      "Epoch 27/50\n",
      "36/36 - 0s - loss: 0.0674 - accuracy: 0.9917 - val_loss: 1.2354 - val_accuracy: 0.6687 - 255ms/epoch - 7ms/step\n",
      "Epoch 28/50\n",
      "36/36 - 0s - loss: 0.0578 - accuracy: 0.9931 - val_loss: 1.1856 - val_accuracy: 0.6687 - 254ms/epoch - 7ms/step\n",
      "Epoch 29/50\n",
      "36/36 - 0s - loss: 0.0518 - accuracy: 0.9931 - val_loss: 1.1539 - val_accuracy: 0.6687 - 254ms/epoch - 7ms/step\n",
      "Epoch 30/50\n",
      "36/36 - 0s - loss: 0.0476 - accuracy: 0.9958 - val_loss: 1.1520 - val_accuracy: 0.6781 - 258ms/epoch - 7ms/step\n",
      "Epoch 31/50\n",
      "36/36 - 0s - loss: 0.0457 - accuracy: 0.9944 - val_loss: 1.1798 - val_accuracy: 0.6812 - 272ms/epoch - 8ms/step\n",
      "Epoch 32/50\n",
      "36/36 - 0s - loss: 0.0338 - accuracy: 0.9986 - val_loss: 1.1700 - val_accuracy: 0.6906 - 261ms/epoch - 7ms/step\n",
      "Epoch 33/50\n",
      "36/36 - 0s - loss: 0.0403 - accuracy: 0.9958 - val_loss: 1.2911 - val_accuracy: 0.6687 - 273ms/epoch - 8ms/step\n",
      "Epoch 34/50\n",
      "36/36 - 0s - loss: 0.0519 - accuracy: 0.9924 - val_loss: 1.3928 - val_accuracy: 0.6812 - 263ms/epoch - 7ms/step\n",
      "Epoch 35/50\n",
      "36/36 - 0s - loss: 0.0372 - accuracy: 0.9972 - val_loss: 1.4390 - val_accuracy: 0.6500 - 271ms/epoch - 8ms/step\n",
      "Epoch 36/50\n",
      "36/36 - 0s - loss: 0.0333 - accuracy: 0.9979 - val_loss: 1.4044 - val_accuracy: 0.6500 - 272ms/epoch - 8ms/step\n",
      "Epoch 37/50\n",
      "36/36 - 0s - loss: 0.0312 - accuracy: 0.9979 - val_loss: 1.4317 - val_accuracy: 0.6812 - 269ms/epoch - 7ms/step\n",
      "Epoch 38/50\n",
      "36/36 - 0s - loss: 0.0235 - accuracy: 0.9986 - val_loss: 1.3347 - val_accuracy: 0.6781 - 273ms/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "36/36 - 0s - loss: 0.0196 - accuracy: 0.9993 - val_loss: 1.3956 - val_accuracy: 0.6781 - 273ms/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "36/36 - 0s - loss: 0.0231 - accuracy: 0.9986 - val_loss: 1.4041 - val_accuracy: 0.6594 - 268ms/epoch - 7ms/step\n",
      "Epoch 41/50\n",
      "36/36 - 0s - loss: 0.0226 - accuracy: 0.9986 - val_loss: 1.4769 - val_accuracy: 0.6531 - 269ms/epoch - 7ms/step\n",
      "Epoch 42/50\n",
      "36/36 - 0s - loss: 0.0187 - accuracy: 0.9986 - val_loss: 1.4183 - val_accuracy: 0.6562 - 251ms/epoch - 7ms/step\n",
      "Epoch 43/50\n",
      "36/36 - 0s - loss: 0.0229 - accuracy: 0.9979 - val_loss: 1.4305 - val_accuracy: 0.6781 - 258ms/epoch - 7ms/step\n",
      "Epoch 44/50\n",
      "36/36 - 0s - loss: 0.0220 - accuracy: 0.9965 - val_loss: 1.3691 - val_accuracy: 0.6875 - 265ms/epoch - 7ms/step\n",
      "Epoch 45/50\n",
      "36/36 - 0s - loss: 0.0181 - accuracy: 0.9993 - val_loss: 1.5664 - val_accuracy: 0.6500 - 251ms/epoch - 7ms/step\n",
      "Epoch 46/50\n",
      "36/36 - 0s - loss: 0.0206 - accuracy: 0.9979 - val_loss: 1.5240 - val_accuracy: 0.6594 - 267ms/epoch - 7ms/step\n",
      "Epoch 47/50\n",
      "36/36 - 0s - loss: 0.0260 - accuracy: 0.9951 - val_loss: 1.6030 - val_accuracy: 0.6469 - 263ms/epoch - 7ms/step\n",
      "Epoch 48/50\n",
      "36/36 - 0s - loss: 0.0309 - accuracy: 0.9944 - val_loss: 1.4911 - val_accuracy: 0.6844 - 259ms/epoch - 7ms/step\n",
      "Epoch 49/50\n",
      "36/36 - 0s - loss: 0.0134 - accuracy: 0.9993 - val_loss: 1.4630 - val_accuracy: 0.6781 - 272ms/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "36/36 - 0s - loss: 0.0175 - accuracy: 0.9986 - val_loss: 1.5259 - val_accuracy: 0.6875 - 268ms/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history_cnn1 = cnn1.fit(train_data, validation_data=val_data, epochs=50, verbose=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47af5f",
   "metadata": {},
   "source": [
    "### 2. Error anaylsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf7dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09a39a88",
   "metadata": {},
   "source": [
    "### 3. Kernel engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d21af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
